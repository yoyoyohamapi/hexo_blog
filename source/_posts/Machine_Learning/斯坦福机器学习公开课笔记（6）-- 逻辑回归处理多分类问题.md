title: 斯坦福机器学习公开课笔记（6）-- 逻辑回归处理多分类问题
tags: 斯坦福机器学习
categories: 斯坦福机器学习公开课笔记
----
###我们采用One-vs-All，或者说是One-vs-the Rest方法来实现多分类

这是将多分类问题转化为了多次二分类问题，具体过程如下：

1. 轮流选中某一类型$i$，将其视为正类型（positive class），即“1”分类，其余剩下样本都看做是负类型（negative class），即“0”分类。

2. 获得i类型的逻辑回归分类器$h_\theta^{(i)}(x)$,即我们的每一步都确定了一个新的类型（获得了一个类型与其他类型的决策边界）。

![multi-class](http://7pulhb.com1.z0.glb.clouddn.com/ml-One-vs-All.png)

假定输入向量$x$。则分别计算{% math h_\theta^{(i)}(x) %},因为我们每个i类型都是视作正类型，即{% math h_\theta^{(i)}(x) %}越大，预测越精确：

![h](http://7pulhb.com1.z0.glb.clouddn.com/ml-h.png)

所以，{% math h_\theta^{(i)}(x) %}越大，$x$越接近是第$i$类。