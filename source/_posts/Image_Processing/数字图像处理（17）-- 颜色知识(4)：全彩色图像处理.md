title: 数字图像处理（17）-- 颜色知识(4)：全彩色图像处理
tags: 数字图像处理
categories: 数字图像处理
-----
全彩色（full color）图像的处理通常有以下两种策略：

1. 对每一个颜色分量（通道）进行处理，得到各个分量的处理结果，最后进行叠加操作。

2. 对整个像素的颜色向量进行处理，得到整个图的处理结果。

先看一个对每个分量进行线性变换的处理，在该例子中，分别在RGB颜色模型和HSV颜色模型中对全彩色图像进行处理。

在RGB颜色模型中，变换函数为：

$s_i=kr_i$  $(i=1,2,3)$

其中，$s_i$为目标颜色分量i强度，$r_i$为原图像颜色分量i强度。

在HSV颜色模型中，变换函数为：

$s_3=kr_3$

即在HSV颜色模型中，只对强度V做线性变化。

当$K=0.75$时，有如下处理结果：

![对V通道做线性变换](http://7pulhb.com1.z0.glb.clouddn.com/ip-对V通道最线性变换.png)

代码如下:

```cpp
#include <iostream>
#include <string>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv/cv.hpp>
#include <fstream>
using namespace std;
using namespace cv;

//图像处理基础素材路径
#define BASEPATH "/Users/feiyu06/Pictures/img_processing/"

#define BYTE unsigned char

int main(int argc, const char * argv[])
{
    //图像路径
    string img_path = "DIP3E_Original_Images_CH06/Fig0631(a)(strawberries_coffee_full_color).tif";
    Mat img = imread(BASEPATH+img_path, 1);
    //img_rgb_processed为rgb颜色模型处理后的图像
    Mat img_rgb_processed;
    //img
    Mat img_hsv_processed;
    cvtColor(img, img_hsv_processed,CV_BGR2HSV);
    img_hsv_processed.convertTo(img_hsv_processed, CV_32F);
    img.convertTo(img, CV_32F);
    //原图像大小
    Size size = img.size();
    //原图像通道数
    int channels_num = img.channels();
    //拆分用通道
    vector<Mat> s_channels(channels_num);
    //合并用通道
    vector<Mat> m_channels(channels_num);
    //************************开始进行RGB颜色空间的亮度降低***************************
    split(img,s_channels);
    //线性变化的k值
    double k = 0.75;
    int i,j;
    for(i=0;i<channels_num;i++){
        //灰度归一化处理
        normalize(s_channels[i], s_channels[i],1.0,0,NORM_MINMAX);
        m_channels[i] = s_channels[i]*k;
    }
    merge(m_channels,img_rgb_processed);
    //****************************************************************************
    
    //***********************开始进行HSV颜色空间的亮度降低****************************
    split(img_hsv_processed,s_channels);
    for(i=0;i<channels_num;i++){
        if(i==2){
            //灰度归一化处理
            m_channels[i] = s_channels[i]*k;
        }
        else
            m_channels[i] = s_channels[i];

    }
    merge(m_channels,img_hsv_processed);
    //将HSV图像转换为BGR图像，方便显示
    convertScaleAbs(img_hsv_processed, img_hsv_processed);
    cvtColor(img_hsv_processed, img_hsv_processed, CV_HSV2BGR);
    //*****************************************************************************
    //接下来是图像显示
    convertScaleAbs(img, img);
    namedWindow("src pic", WINDOW_AUTOSIZE);
    namedWindow("rgb processed pic",WINDOW_AUTOSIZE);
    namedWindow("hsv processed pic",WINDOW_AUTOSIZE);
    imshow("src pic", img);
    imshow("rgb processed pic",img_rgb_processed);
    imshow("hsv processed pic",img_hsv_processed);
    waitKey(0);
    //return
    return 0;
}
```

可以看到，在RGB颜色模型和HSV颜色模型中，达到了相同的降低亮度的效果，然而HSV中只需对强度V这一个分量进行操作即可，这也体现出了HSV的__“分离了灰度（亮度）和颜色信息”__这一优势。

##彩色分割

进行彩色分割的目的就在于突出图像中感兴趣的区域，由于彩色图像多是定义在三维空间，所以感兴趣的区域不再是平面线段，而是空间立体区域，通常有：

立方体区域：

$s_i=\begin{cases}0.5&\text{if }[|r_j-a_j|> \frac{w}{2}]_{any 1\leq{j}\leq{n}}\\r_i&\text{otherwise}\end{cases}$  $i=1,2,3....,n$

其中，$a_j$为感兴趣的颜色分量$j$,$W$为感兴趣颜色立方体边长,$W$也可看做是最大不能偏离兴趣颜色分量的距离。考虑某颜色分量与感兴趣的颜色分量间的差值关系，若有任意一对分量差超过$\frac{W}{2}$,则输出的颜色分量被标定为$0.5$。

例如，若感兴趣的颜色分量为(0.2,0.3,0.5),W=0.2,则$\frac{W}{2}$=0.1;考虑某像素的颜色为(0,1,0,4,0.3)，那么颜色分量$r_2=0.4$的输出应为多少？

因为：

$|0.1-0.2|=0.1\leq\frac{W}{2}$

$|0.4-0.3|=0.1\leq\frac{W}{2}$

$|0.3-0.5|=0.2\gt\frac{W}{2}$

故颜色分量$r_2=0.4$的输出应为$s_2=0.5$

球体区域：

$s_i=\begin{cases}0.5&\text{if }\sum\limits_{j=1}^n(r_j-a_j)^2\gt R_0^2\\r_i&\text{otherwise}\end{cases}$

其中，$R_0$为球体半径

如下图所示，采用的$W=0.1049$，突出显示了草莓区域：

![彩色图像分割](http://7pulhb.com1.z0.glb.clouddn.com/ip-彩色分割.png)

代码如下：

```cpp
#include <iostream>
#include <string>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv/cv.hpp>
#include <fstream>
using namespace std;
using namespace cv;

//图像处理基础素材路径
#define BASEPATH "/Users/feiyu06/Pictures/img_processing/"

#define BYTE unsigned char

int main(int argc, const char * argv[])
{
    //图像路径
    string img_path = "DIP3E_Original_Images_CH06/Fig0631(a)(strawberries_coffee_full_color).tif";
    Mat img = imread(BASEPATH+img_path, 1);
    img.convertTo(img, CV_32FC3);
    Mat img_dst = img.clone();
    
    //设定立方体边长
    float W = 0.1049;
    //感兴趣的颜色
    vector<float> itst = {0.1922,0.1608,0.6863};
    Mat interest(itst);
    //用于分离通道
    vector<Mat> s_channels(img.channels());
    split(img,s_channels);
    int i,j,k;
    //标定每一个通道
    for(k=0;k<img.channels();k++){
        normalize(s_channels[k],s_channels[k],1.0,0.0,NORM_MINMAX);
    }    //遍历像素
    merge(s_channels, img);
    for(i=0;i<img.rows;i++)
        for(j=0;j<img.cols;j++){
            Mat r = interest.clone();
            r.at<float>(0,0) = img.at<Vec3f>(i,j)[0];
            r.at<float>(1,0) = img.at<Vec3f>(i,j)[1];
            r.at<float>(2,0) = img.at<Vec3f>(i,j)[2];
            double max,min;
            //获得距离矩阵
            Mat distance = abs(r-interest);
            minMaxLoc(distance, &min, &max);
            for(k=0;k<img.channels();k++){
                if( min > (W/2.0) )
                    img_dst.at<Vec3f>(i,j)[k]=0.5;
                else
                    img_dst.at<Vec3f>(i,j)[k]=r.at<float>(k,0);
                
            }
        }
    namedWindow("src image",WINDOW_AUTOSIZE);
    namedWindow("dst image",WINDOW_AUTOSIZE);
    imshow("src image",img);
    imshow("dst image", img_dst);
    waitKey(0);
    //return
    return 0;
}
```

##直方图处理：

彩色图像的直方图处理通常只需要在灰度级完成，而非对每个颜色通道都进行直方图操作，故而我们在彩色图像的直方图处理中考虑使用HSI（HSV）颜色模型。

下面我们看一则例子,这则例子中，原图像亮度偏暗，操作其V通道进行直方图均衡化处理，加强了亮度：

![V通道直方图均衡化](http://7pulhb.com1.z0.glb.clouddn.com/ip-直方图处理.png)

![直方图对比](http://7pulhb.com1.z0.glb.clouddn.com/ip-直方图对比.png)
 

##彩色图像模糊与锐化：
在RGB颜色空间中，一般的线性处理（如均值滤波）分别作用在各通道的结果等于直接作用在颜色向量的结果，然而，如统计排序滤波（如中值滤波等）这些非线性操作就不适用了，你很难衡量向量间的大小关系。

通常，为了不影响彩色图像的颜色信息，我们更乐意在HSV图像下的V通道（即灰度图）下进行图像的模糊处理。下面是一则例子，在这则例子中，分别对RGB图像的三个通道做均值滤波处理，而在HSV图像的V通道做均值滤波，在第四幅图（用对数进行过对比度增强，实际差异较小）中可以看到，二者的模糊效果还是有所差异：

![彩色图像模糊](http://7pulhb.com1.z0.glb.clouddn.com/ip-彩色图像锐化.png)

代码如下：

```cpp
#include <iostream>
#include <string>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv/cv.hpp>
#include <fstream>
using namespace std;
using namespace cv;

//图像处理基础素材路径
#define BASEPATH "/Users/feiyu06/Pictures/img_processing/"

#define BYTE unsigned char

int main(int argc, const char * argv[])
{
    //图像路径
    string img_path = "DIP3E_Original_Images_CH06/Fig0638(a)(lenna_RGB).tif";
    Mat img = imread(BASEPATH+img_path, 1);
    Mat img_bgr = img.clone();
    //将图像转换到HSV颜色空间
    Mat img_hsv;
    cvtColor(img, img_hsv, CV_BGR2HSV);
    //分离用通道
    vector<Mat>  s_channels(img.channels());
    //合并用通道
    vector<Mat> m_channels(img.channels());
    int i;
    //*********************************完成RGB图像的模糊处理***********************************************
    split(img_bgr,s_channels);
    //对各通道进行均值滤波
    for(i=0;i<img_bgr.channels();i++){
        blur(s_channels[i], m_channels[i],{3,3});
    }
    merge(m_channels,img_bgr);
    //*********************************完成HSV图像的模糊处理***********************************************
    split(img_hsv,s_channels);
    //仅对V通道进行均值滤波
    for(i=0;i<img_hsv.channels();i++){
        if(i==2)
            blur(s_channels[i], m_channels[i], {3,3});
        else
            m_channels[i] = s_channels[i];
    }
    merge(m_channels,img_hsv);
    //讲HSV图像转换为RGB图像，方便显示
    cvtColor(img_hsv, img_hsv, CV_HSV2BGR);
    //HSV模糊处理与RGB模糊处理的差异图像
    Mat diff = img_bgr - img_hsv;
    cvtColor(diff,diff,CV_BGR2GRAY);
    diff.convertTo(diff, CV_32F);
    log(diff, diff);
    namedWindow("src image",WINDOW_AUTOSIZE);
    namedWindow("RGB image blured",WINDOW_AUTOSIZE);
    namedWindow("HSV image blured",WINDOW_AUTOSIZE);
    namedWindow("The difference of bluring",WINDOW_AUTOSIZE);
    imshow("src image",img);
    imshow("RGB image blured", img_bgr);
    imshow("HSV image blured",img_hsv);
    imshow("The difference of bluring",diff);
    waitKey(0);
    //return
    return 0;
}
```

下例是锐化操作，锐化滤波器为拉普拉斯滤波器，直接对RGB图像进行滤波：

![彩色图像锐化](http://7pulhb.com1.z0.glb.clouddn.com/ip-直接对RGB图像锐化.png)

##HSV颜色空间的颜色分割（突出颜色区域）：

在__冈萨雷斯的《数字图像处理》__中其实还有提到RGB颜色空间的颜色分离，但实现起来比较复杂，在此不讨论，HSV颜色空间通过色调(hue)和饱和度(saturation)就能很好地确定颜色信息，相当方便。

在HSV颜色空间的颜色分割的实现经历如下步骤：

1. 分离出Hue通道（首先，颜色参与提名“需要突出颜色”）

2. 分离出Saturation通道，并且二值化为0、1，用二值化后的饱和度图像作为掩膜，与色度图像做点积（淘汰那些饱和度不够的提名色）

下面是例子，该例子中，原图像色泽较为浓郁的区域被突出（最右下角图片）：

![HSV颜色分割](http://7pulhb.com1.z0.glb.clouddn.com/ip-HSV颜色分割.png)

![HSV颜色分割2](http://7pulhb.com1.z0.glb.clouddn.com/ip-HSV颜色分割2.png)

(a)原图像 (b)Hue通道 (c)饱和度通道

(d)二值化的饱和度通道 (e)分割后图像


代码如下：

```cpp
#include <iostream>
#include <string>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv/cv.hpp>
#include <fstream>
using namespace std;
using namespace cv;

//图像处理基础素材路径
#define BASEPATH "/Users/feiyu06/Pictures/img_processing/"

#define BYTE unsigned char

int main(int argc, const char * argv[])
{
    //图像路径
    string img_path = "DIP3E_Original_Images_CH06/Fig0642(a)(jupiter_moon_original).tif";
    Mat img = imread(BASEPATH+img_path, 1);
    //将图像转换到HSV颜色空间
    Mat img_hsv;
    cvtColor(img, img_hsv, CV_BGR2HSV);
    //分离用通道
    vector<Mat>  s_channels(img.channels());
    //合并用通道
    vector<Mat> m_channels(img.channels());
    //分离HSV图像各个通道
    split(img_hsv,s_channels);
    //设置饱和度阈值
    s_channels[1].convertTo(m_channels[1], CV_32F);
    m_channels[0] = s_channels[0];
    double min,max;
    minMaxLoc(m_channels[1],&min,&max);
    cout<<max<<endl;
    double thresh = max*0.3;
    //二值化饱和度图像
    threshold(m_channels[1], m_channels[1], thresh,1.0, THRESH_BINARY);
    m_channels[1].convertTo(m_channels[1], CV_8U);
    //二值化后的饱和度图像与色度图像点积获得最终颜色分割图像
    Mat img_dst;
    multiply(m_channels[0], m_channels[1], img_dst);
    m_channels[1].convertTo(m_channels[1],CV_32F);
    namedWindow("Src image",WINDOW_AUTOSIZE);
    namedWindow("Hue image",WINDOW_AUTOSIZE);
    namedWindow("Saturation image",WINDOW_AUTOSIZE);
    namedWindow("Binary Saturation mask",WINDOW_AUTOSIZE);
    namedWindow("Dst image",WINDOW_AUTOSIZE);
    imshow("Src image",img);
    imshow("Hue image", m_channels[0]);
    imshow("Saturation image",s_channels[1]);
    imshow("Binary Saturation mask",m_channels[1]);
    imshow("Dst image", img_dst);
    waitKey(0);
    //return
    return 0;
}
```

##全彩色图像的边缘检测：

因为梯度（反映图像灰度变化）在向量中的定义不同于标量中的定义，故而在灰度图像中的梯度算法并不能直接作用于全彩色图像。通常，在RGB颜色模型中，我们会对各分量进行边缘检测后再叠加。

如下例子所示，我们对彩色图像的各分量图像做边缘检测后进行叠加，在这里，所用到边缘检测算法是Canny边缘检测。注意到：

>Canny算法中减少假边缘数量的方法是采用双阈值法。选择两个阈值（关于阈值的选取方法在扩展中进行讨论），根据高阈值得到一个边缘图像，这样一个图像含有很少的假边缘，但是由于阈值较高，产生的图像边缘可能不闭合，未解决这样一个问题采用了另外一个低阈值。

>在高阈值图像中把边缘链接成轮廓，当到达轮廓的端点时，该算法会在断点的8邻域点中寻找满足低阈值的点，再根据此点收集新的边缘，直到整个图像边缘闭合。

在此，我们通过滑动条来控制高、低阈值：

![彩色图像边缘检测](http://7pulhb.com1.z0.glb.clouddn.com/ip-全彩色图像边缘检测.png)

代码如下:

```cpp
#include <iostream>
#include <string>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv/cv.hpp>
#include <fstream>
using namespace std;
using namespace cv;

//图像处理基础素材路径
#define BASEPATH "/Users/feiyu06/Pictures/img_processing/"
#define BYTE unsigned char

//定义滑动条基本参数
int high_thresh = 255;
int low_thresh = 0;
const int max_val = 255;
string winname = "Edges Detecting....";
//原图像
Mat img;
//边缘图像
Mat edges_img;

void edgesDetecting(int,void*);

int main(int argc, const char * argv[])
{
    //图像路径
    string img_path = "DIP3E_Original_Images_CH06/Fig0638(a)(lenna_RGB).tif";
    img = imread(BASEPATH+img_path, 1);
    namedWindow(winname,WINDOW_AUTOSIZE);
    createTrackbar("High Threshold", winname, &high_thresh, max_val,edgesDetecting);
    createTrackbar("Low Threshold", winname, &low_thresh,max_val, edgesDetecting);
    edgesDetecting(0, 0);
    namedWindow("Src Image",WINDOW_AUTOSIZE);
    imshow("Src Image",img);
    waitKey(0);
    //return
    return 0;
}

//定义根据滑动条参数设定来完成边缘检测
void edgesDetecting(int,void*){
    //分离用通道
    vector<Mat> s_channels(img.channels());
    //合并用通道
    vector<Mat> m_channels(img.channels());
    split(img,s_channels);
    int i;
    //对各通道进行边缘检测
    for(i=0;i<img.channels();i++)
        Canny(s_channels[i], m_channels[i], high_thresh, low_thresh);
    merge(m_channels, edges_img);
    imshow(winname, edges_img);
}
```